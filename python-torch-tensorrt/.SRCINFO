pkgbase = python-torch-tensorrt
	pkgdesc = Easily achieve the best inference performance for any PyTorch model on the NVIDIA platform
	pkgver = 2.9.0
	pkgrel = 5
	url = https://github.com/pytorch/TensorRT
	arch = x86_64
	license = BSD-3-Clause
	makedepends = python-build
	makedepends = python-installer
	makedepends = python-wheel
	makedepends = python-setuptools
	makedepends = pybind11
	makedepends = python-ninja
	depends = python
	depends = python-pytorch-cuda
	depends = python-numpy
	depends = python-packaging
	depends = python-typing_extensions
	depends = python-dllist
	depends = python-tensorrt
	depends = python-rich
	depends = python-nvidia-modelopt
	depends = python-torchvision
	depends = cuda
	depends = tensorrt
	optdepends = python-pydot: for engine visualization features
	optdepends = python-graphviz: for graph utilities
	optdepends = tensorrt-llm: for LLM inference support
	source = python-torch-tensorrt-2.9.0.tar.gz::https://github.com/pytorch/TensorRT/archive/refs/tags/v2.9.0.tar.gz
	source = fix-glog-0.7.patch
	sha256sums = 9d1db6aa671d73be102ecd79e7045bc1dad9e20b97b7a5b4992f94d3642c904e
	sha256sums = 4a7413873885f73d7e3fa142308953225a6b3af4d0969707e75bfcadf046e9b8
	source_x86_64 = bazel-8.1.1::https://github.com/bazelbuild/bazel/releases/download/8.1.1/bazel-8.1.1-linux-x86_64
	sha256sums_x86_64 = a2a095d7006ea70bdfdbe90a71f99f957fee1212d4614cfcfdbe3aadae681def

pkgname = python-torch-tensorrt
