pkgbase = vllama
	pkgdesc = vLLM + Ollama hybrid server - Fast inference with Ollama model management
	pkgver = 0.2.0
	pkgrel = 5
	url = https://github.com/erkkimon/vllama
	install = vllama.install
	arch = x86_64
	license = MIT
	makedepends = python-setuptools
	makedepends = git
	depends = python
	depends = ollama
	depends = python-pip
	depends = python-setuptools
	source = vllama-40602f1e70f3ca4fd98f7f7ff77deddeeda3040b.tar.gz::https://github.com/erkkimon/vllama/archive/40602f1e70f3ca4fd98f7f7ff77deddeeda3040b.tar.gz
	source = vllama.service
	source = multiuser.conf
	source = vllama.install
	sha256sums = 7664ce171d46ae02e7c61e0217c7cc73b2e13b570cb536c69826dcdd5e2b5de0
	sha256sums = 32f30f302919e881bf3205320b9f8c5dc7720738223bb035a26f856cdc9cf882
	sha256sums = 316d741d3c15533002b0607d88ac9231c72258e5e856bd470805a8ba1b9ee29f
	sha256sums = 1d84cd4dab610669264163810c15a0101750a5764ccdd37f13aab061094f23bf

pkgname = vllama
