pkgbase = ollama-bin
	pkgdesc = Create, run and share large language models (LLMs)
	pkgver = 0.12.5
	pkgrel = 1
	url = https://github.com/ollama/ollama
	arch = x86_64
	license = MIT
	optdepends = ollama-cuda: NVIDIA GPU Support
	provides = ollama
	conflicts = ollama
	backup = etc/ollama.conf
	source = LICENSE-0.12.5::https://raw.githubusercontent.com/ollama/ollama/v0.12.5/LICENSE
	source = README-0.12.5.md::https://raw.githubusercontent.com/ollama/ollama/v0.12.5/README.md
	sha256sums = 5934ed2ce0d15154bcdb9c85203210abac0da4314af34081e36df4599f90b226
	sha256sums = 0f1dc155b5139c6e6aea8cbe7541a4ba6065c0674662cf35f58a21514c05ff2e
	source_x86_64 = ollama-x86_64-0.12.5.tgz::https://github.com/ollama/ollama/releases/download/v0.12.5/ollama-linux-amd64.tgz
	source_x86_64 = ollama.conf
	source_x86_64 = ollama.service
	source_x86_64 = sysusers.conf
	source_x86_64 = tmpfiles.d
	sha256sums_x86_64 = e0d20dac3358403ef17f880168f32a59b911f3875c509d2d256bd70acce9360e
	sha256sums_x86_64 = 2503546a6d26559bce06ba6c61100026d85864b4c49bd6e4c80c596c5d22e197
	sha256sums_x86_64 = 24871ffd940212e04e9bd3c334cfd4e3c4e845b374c5d0ed369fd32496b05fdb
	sha256sums_x86_64 = 14e2e267be85b6943f66dfe60e73f5e0a611eaf40ee69a4cc0d497d071392cf4
	sha256sums_x86_64 = 137e1d50a5f3058c30a73b7bb3c323888d225e6a7ae47564be869827db0659a3

pkgname = ollama-bin

pkgname = ollama-cuda12-bin
	pkgdesc = Create, run and share large language models (LLMs) with CUDA 12
	depends = ollama-bin
	provides = ollama-cuda
	conflicts = ollama-cuda

pkgname = ollama-cuda13-bin
	pkgdesc = Create, run and share large language models (LLMs) with CUDA 13
	depends = ollama-bin
	provides = ollama-cuda
	conflicts = ollama-cuda
