pkgbase = ollama-bin
	pkgdesc = Create, run and share large language models (LLMs)
	pkgver = 0.12.6
	pkgrel = 1
	url = https://github.com/ollama/ollama
	arch = x86_64
	license = MIT
	optdepends = ollama-cuda: NVIDIA GPU Support
	provides = ollama
	conflicts = ollama
	backup = etc/ollama.conf
	source = LICENSE-0.12.6::https://raw.githubusercontent.com/ollama/ollama/v0.12.6/LICENSE
	source = README-0.12.6.md::https://raw.githubusercontent.com/ollama/ollama/v0.12.6/README.md
	sha256sums = 5934ed2ce0d15154bcdb9c85203210abac0da4314af34081e36df4599f90b226
	sha256sums = 922bd9e4d2cc01292e94e85aa423c6ea7ca8fff129110ed89c099dd7d636dced
	source_x86_64 = ollama-x86_64-0.12.6.tgz::https://github.com/ollama/ollama/releases/download/v0.12.6/ollama-linux-amd64.tgz
	source_x86_64 = ollama.conf
	source_x86_64 = ollama.service
	source_x86_64 = sysusers.conf
	source_x86_64 = tmpfiles.d
	sha256sums_x86_64 = de82adce2ab79235115d511ff22fcb099ac53b67127870f12b80198c033ec0a1
	sha256sums_x86_64 = 2503546a6d26559bce06ba6c61100026d85864b4c49bd6e4c80c596c5d22e197
	sha256sums_x86_64 = 24871ffd940212e04e9bd3c334cfd4e3c4e845b374c5d0ed369fd32496b05fdb
	sha256sums_x86_64 = 14e2e267be85b6943f66dfe60e73f5e0a611eaf40ee69a4cc0d497d071392cf4
	sha256sums_x86_64 = 137e1d50a5f3058c30a73b7bb3c323888d225e6a7ae47564be869827db0659a3

pkgname = ollama-bin

pkgname = ollama-cuda12-bin
	pkgdesc = Create, run and share large language models (LLMs) with CUDA 12
	depends = ollama-bin
	provides = ollama-cuda
	conflicts = ollama-cuda

pkgname = ollama-cuda13-bin
	pkgdesc = Create, run and share large language models (LLMs) with CUDA 13
	depends = ollama-bin
	provides = ollama-cuda
	conflicts = ollama-cuda
