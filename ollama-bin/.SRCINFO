pkgbase = ollama-bin
	pkgdesc = Create, run and share large language models (LLMs)
	pkgver = 0.12.10
	pkgrel = 1
	url = https://github.com/ollama/ollama
	arch = x86_64
	license = MIT
	depends = glibc
	depends = gcc-libs
	optdepends = ollama-cuda: NVIDIA GPU Support
	provides = ollama
	conflicts = ollama
	backup = etc/ollama.conf
	source = LICENSE-0.12.10::https://raw.githubusercontent.com/ollama/ollama/v0.12.10/LICENSE
	source = README-0.12.10.md::https://raw.githubusercontent.com/ollama/ollama/v0.12.10/README.md
	sha256sums = 5934ed2ce0d15154bcdb9c85203210abac0da4314af34081e36df4599f90b226
	sha256sums = b2e4561b83730ea40fea2d91cc7003c2cbd1e715d4ef19b6fa22240f7ab88d1e
	source_x86_64 = ollama-x86_64-0.12.10.tgz::https://github.com/ollama/ollama/releases/download/v0.12.10/ollama-linux-amd64.tgz
	source_x86_64 = ollama.conf
	source_x86_64 = ollama.service
	source_x86_64 = sysusers.conf
	source_x86_64 = tmpfiles.d
	sha256sums_x86_64 = 8f4bf70a9856a34ba71355745c2189a472e2691a020ebd2e242a58e4d2094722
	sha256sums_x86_64 = 2503546a6d26559bce06ba6c61100026d85864b4c49bd6e4c80c596c5d22e197
	sha256sums_x86_64 = 24871ffd940212e04e9bd3c334cfd4e3c4e845b374c5d0ed369fd32496b05fdb
	sha256sums_x86_64 = 14e2e267be85b6943f66dfe60e73f5e0a611eaf40ee69a4cc0d497d071392cf4
	sha256sums_x86_64 = 137e1d50a5f3058c30a73b7bb3c323888d225e6a7ae47564be869827db0659a3

pkgname = ollama-bin

pkgname = ollama-cuda12-bin
	pkgdesc = Create, run and share large language models (LLMs) with CUDA 12
	depends = glibc
	depends = gcc-libs
	depends = ollama-bin
	provides = ollama-cuda
	conflicts = ollama-cuda

pkgname = ollama-cuda13-bin
	pkgdesc = Create, run and share large language models (LLMs) with CUDA 13
	depends = glibc
	depends = gcc-libs
	depends = ollama-bin
	provides = ollama-cuda
	conflicts = ollama-cuda
