pkgbase = python-open-clip-torch
	pkgdesc = Open source implementation of OpenAI's CLIP (Contrastive Language-Image Pre-training).
	pkgver = 2.30.0
	pkgrel = 1
	url = https://github.com/mlfoundations/
	arch = any
	license = MIT
	makedepends = python-build
	makedepends = python-installer
	makedepends = python-wheel
	depends = python-braceexpand
	depends = python-fsspec
	depends = python-ftfy
	depends = python-horovod
	depends = python-huggingface-hub
	depends = python-nltk
	depends = python-pandas
	depends = python-regex
	depends = python-safetensors
	depends = python-sentencepiece
	depends = python-timm
	depends = python-torchvision
	depends = python-tqdm
	depends = python-transformers
	depends = python-wandb
	depends = python-webdataset
	source = https://github.com/mlfoundations/open_clip/archive/refs/tags/v2.30.0.zip
	sha256sums = 8537e54025314884b5a2bb221ef6c1c9b76c6eccea2e54eef33e94de9b2305d7

pkgname = python-open-clip-torch
